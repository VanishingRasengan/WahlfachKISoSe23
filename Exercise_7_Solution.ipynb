{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanishingRasengan/WahlfachKISoSe23/blob/main/Exercise_7_Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5yOkGTUF6Kp"
      },
      "source": [
        " ## Setting up a network model and starting a first training\n",
        "\n",
        "In this and the following exercise, we are going to practise, how to set up a neural network model and perform a first training with this network.\n",
        "We will use the DermaMNIST from the MedMNIST datasets, which you have seen last lecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnthk05cBlAV"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import sys\n",
        "# from tqdm import trange\n",
        "# from tqdm import tqdm\n",
        "# from skimage.util import montage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision as torchvision\n",
        "\n",
        "!pip install medmnist\n",
        "import medmnist\n",
        "from medmnist.dataset import PathMNIST, ChestMNIST, DermaMNIST, OCTMNIST, PneumoniaMNIST, RetinaMNIST, BreastMNIST, OrganMNISTAxial, OrganMNISTCoronal, OrganMNISTSagittal\n",
        "from medmnist.evaluator import getAUC, getACC\n",
        "from medmnist.info import INFO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGpKZ1TFwfnL"
      },
      "outputs": [],
      "source": [
        "print(\"Version:\", medmnist.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6nPfDx8wiAR"
      },
      "outputs": [],
      "source": [
        "# various MedMNIST datasets\n",
        "data_flag = 'dermamnist'\n",
        "download = True\n",
        "input_root = 'tmp_data/'\n",
        "!mkdir 'tmp_data'\n",
        "\n",
        "flag_to_class = {\n",
        "    \"pathmnist\": PathMNIST,\n",
        "    \"chestmnist\": ChestMNIST,\n",
        "    \"dermamnist\": DermaMNIST,\n",
        "    \"octmnist\": OCTMNIST,\n",
        "    \"pneumoniamnist\": PneumoniaMNIST,\n",
        "    \"retinamnist\": RetinaMNIST,\n",
        "    \"breastmnist\": BreastMNIST,\n",
        "    \"organmnist_axial\": OrganMNISTAxial,\n",
        "    \"organmnist_coronal\": OrganMNISTCoronal,\n",
        "    \"organmnist_sagittal\": OrganMNISTSagittal,\n",
        "}\n",
        "\n",
        "DataClass = flag_to_class[data_flag]\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "label_dict = info['label']\n",
        "\n",
        "print(f\"Info:\\n{info}\\n\")\n",
        "print(f\"Task:\\n{task}\\n\")\n",
        "print(f\"Channels:\\n{n_channels}\\n\")\n",
        "print(f\"Number of classes:\\n{n_classes}\\n\")\n",
        "print(f\"Label:\\n{label_dict}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2I6F49b8fRx",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Defining the augmentations\n",
        "\n",
        "As described in the last exercise, we now define the augmentations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjF-Aq9BF6K_",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Imagenet values\n",
        "norm_mean = (0.4914)\n",
        "norm_std = (0.2023)\n",
        "\n",
        "# define the transformaitons the images go through each time it is used for training\n",
        "# includes augmentation AND normalization as described above\n",
        "augmentation_train = transforms.Compose([\n",
        "                                  # resize image to the network input size\n",
        "                                  transforms.Resize((28,28)),\n",
        "                                  # rotate the image with a certain angle range, randomly chosen\n",
        "                                  transforms.RandomRotation(degrees=20),\n",
        "                                  # convert the image into a tensor so it can be processed by the GPU\n",
        "                                  transforms.ToTensor(),\n",
        "                                  # normalize the image with the mean and std of ImageNet\n",
        "                                  transforms.Normalize(norm_mean, norm_std),\n",
        "                                   ])\n",
        "\n",
        "# no augmentation for the test data only resizing, conversion to tensor and normalization\n",
        "augmentation_test = transforms.Compose([\n",
        "                    transforms.Resize((28,28)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(norm_mean, norm_std),\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGR6pIuMJsqK"
      },
      "source": [
        "## Splitting up data\n",
        "\n",
        "Set up datasets for training, validation and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHYTu04_yDvo"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "train_dataset = DataClass(root=input_root, split='train', transform=augmentation_train, download=download)\n",
        "test_dataset = DataClass(root=input_root, split='test', transform=augmentation_test, download=download)\n",
        "val_dataset = DataClass(root=input_root, split='val', transform=augmentation_test, download=download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL9p3c52xpUB"
      },
      "outputs": [],
      "source": [
        "# Some detailed information about all splits\n",
        "print(\"===================\")\n",
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(val_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPZXPqSvKNyh"
      },
      "source": [
        "## Create Dataloaders\n",
        "\n",
        "PyTorch provides template Dataloader classes for easy data handling, assigning according transforms and splits. You can find more information about how PyTorch handles datasets and data loading [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUURp9J01EtJ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "### encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMfm-GkQyFe3"
      },
      "outputs": [],
      "source": [
        "### the next() function returns the next item from the iterator.\n",
        "batch_images, batch_labels = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O9BTWgOyIhK"
      },
      "outputs": [],
      "source": [
        "# show all 3 channels of image 10\n",
        "print(batch_images[0].shape)\n",
        "\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(batch_images[11][0,:,:])\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(batch_images[11][1,:,:])\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(batch_images[11][2,:,:])\n",
        "\n",
        "### different color maps\n",
        "### cmap='bone', cmap = 'summer', cmap = 'seismic'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3QclrDwU6j2B"
      },
      "source": [
        "## Define a Convolutional Neural Network\n",
        "\n",
        "Pytorch makes it very easy to define a neural network. We have layers like Convolutions, ReLU non-linearity, Maxpooling etc. directly from [torch library](https://pytorch.org/docs/stable/nn.html).\n",
        "\n",
        "In this tutorial, we use The LeNet architecture introduced by LeCun et al. in their 1998 paper, [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf). As the name of the paper suggests, the authorsâ€™ implementation of LeNet was used primarily for OCR and character recognition in documents. The LeNet architecture is straightforward and small, (in terms of memory footprint), making it perfect for teaching the basics of CNNs.\n",
        "\n",
        "To define a neural network in PyTorch one has to create a class inhereting from [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). Crucially, this class has to include the function forward() which defines which computation should be performed at every call given a batch of inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4SswIxD6j2B",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_classes = 7\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5,5), padding=2)\n",
        "        self.nonlin1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5))\n",
        "        self.nonlin2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n",
        "        self.nonlin3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.nonlin4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
        "        self.nonlin5 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.nonlin1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.nonlin2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.nonlin3(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.nonlin4(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.nonlin5(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeYDXWn0pBF6"
      },
      "source": [
        "You can use torchsummary to print out the architecture of your model given a certain input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpD04oeOpBF6"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = LeNet()\n",
        "model.to(device)\n",
        "\n",
        "summary(model, input_size=(1,28,28), batch_size=127)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hf87hhWCaqp"
      },
      "source": [
        "## Homework\n",
        "\n",
        "Create a neural network capable of processing the image tensor 'img', which has only one channel. The network should contain at least one convolutional layer and one additional fully connected layer. Pay attention that within the fully connected layer the output dimension of the last convolutional layer has to fit the input dimension. Additionally, the output dimension of the fully connected layer before 'fc_fin' has to match the required input dimension of 'fc_fin'.\n",
        "\n",
        "Some hints:\n",
        "\n",
        "- Have a look at how LeNet is implemented above. Many concepts can be copied.\n",
        "- Focus on using the PyTorch's Linear, Conv2d, MaxPool2d and ReLU layers and the .view() function. You can find detailed information on these components in [PyTorch's documentation](https://pytorch.org/docs/stable/index.html).\n",
        "- Batch size does not have to be considered when designing the neural networks. PyTorch adapts the calculations automatically when provided with different batch sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ia2S8hrDCIL"
      },
      "outputs": [],
      "source": [
        "img = torch.rand((1, 1, 200, 200))\n",
        "\n",
        "output_dim = 6\n",
        "\n",
        "class LeNet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet2, self).__init__()\n",
        "\n",
        "        # --------------------\n",
        "\n",
        "        ########## Insert your layers here ##########\n",
        "        self.conv1 = nn.Conv2d(1, 6, (5,5), padding=2)\n",
        "        self.nonlin1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, (5,5))\n",
        "        self.fc1   = nn.Linear(16*48*48, 120)\n",
        "        self.fc2   = nn.Linear(120, 48)\n",
        "        # --------------------\n",
        "\n",
        "        self.fc_fin = nn.Linear(in_features=48, out_features=output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # --------------------\n",
        "\n",
        "        ########## Insert your forward pass here ##########\n",
        "        x = self.conv1(x)\n",
        "        x = self.nonlin1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), (2,2))\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # --------------------\n",
        "\n",
        "        x = self.fc_fin(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "model = LeNet2()\n",
        "\n",
        "output = model(img)\n",
        "\n",
        "if output.size(1) == 6:\n",
        "    print('The correct output size has been generated.')\n",
        "else:\n",
        "    print('The generated output size is not correct')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('default')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "62f47e0a940d9130cb9d8ad31b00082fdc26fbada418265db41289562a6ad16c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}