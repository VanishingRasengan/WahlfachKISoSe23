{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanishingRasengan/WahlfachKISoSe23/blob/main/%20Lektion_6_Python_f%C3%BCr_Mediziner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5yOkGTUF6Kp"
      },
      "source": [
        " ## Setting up a network model and starting a first training\n",
        "\n",
        "In this and the following exercise, we are going to practise, how to set up a neural network model and perform a first training with this network.\n",
        "We will use the DermaMNIST from the MedMNIST datasets, which you have seen last lecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnthk05cBlAV"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import sys\n",
        "# from tqdm import trange\n",
        "# from tqdm import tqdm\n",
        "# from skimage.util import montage\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision as torchvision\n",
        "\n",
        "!pip install medmnist\n",
        "import medmnist\n",
        "from medmnist.dataset import PathMNIST, ChestMNIST, DermaMNIST, OCTMNIST, PneumoniaMNIST, RetinaMNIST, BreastMNIST, OrganMNISTAxial, OrganMNISTCoronal, OrganMNISTSagittal\n",
        "from medmnist.evaluator import getAUC, getACC\n",
        "from medmnist.info import INFO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGpKZ1TFwfnL"
      },
      "outputs": [],
      "source": [
        "print(\"Version:\", medmnist.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6nPfDx8wiAR"
      },
      "outputs": [],
      "source": [
        "# various MedMNIST datasets\n",
        "data_flag = 'dermamnist'\n",
        "download = True\n",
        "input_root = 'tmp_data/'\n",
        "!mkdir 'tmp_data'\n",
        "\n",
        "flag_to_class = {\n",
        "    \"pathmnist\": PathMNIST,\n",
        "    \"chestmnist\": ChestMNIST,\n",
        "    \"dermamnist\": DermaMNIST,\n",
        "    \"octmnist\": OCTMNIST,\n",
        "    \"pneumoniamnist\": PneumoniaMNIST,\n",
        "    \"retinamnist\": RetinaMNIST,\n",
        "    \"breastmnist\": BreastMNIST,\n",
        "    \"organmnist_axial\": OrganMNISTAxial,\n",
        "    \"organmnist_coronal\": OrganMNISTCoronal,\n",
        "    \"organmnist_sagittal\": OrganMNISTSagittal,\n",
        "}\n",
        "\n",
        "DataClass = flag_to_class[data_flag]\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "label_dict = info['label']\n",
        "\n",
        "print(f\"Info:\\n{info}\\n\")\n",
        "print(f\"Task:\\n{task}\\n\")\n",
        "print(f\"Channels:\\n{n_channels}\\n\")\n",
        "print(f\"Number of classes:\\n{n_classes}\\n\")\n",
        "print(f\"Label:\\n{label_dict}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2I6F49b8fRx",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Defining the augmentations\n",
        "\n",
        "As described in the last exercise, we now define the augmentations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjF-Aq9BF6K_",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Imagenet values\n",
        "norm_mean = (0.4914)\n",
        "norm_std = (0.2023)\n",
        "\n",
        "# define the transformaitons the images go through each time it is used for training\n",
        "# includes augmentation AND normalization as described above\n",
        "augmentation_train = transforms.Compose([\n",
        "                                  # resize image to the network input size\n",
        "                                  transforms.Resize((28,28)),\n",
        "                                  # rotate the image with a certain angle range, randomly chosen\n",
        "                                  transforms.RandomRotation(degrees=20),\n",
        "                                  # convert the image into a tensor so it can be processed by the GPU\n",
        "                                  transforms.ToTensor(),\n",
        "                                  # normalize the image with the mean and std of ImageNet\n",
        "                                  transforms.Normalize(norm_mean, norm_std),\n",
        "                                   ])\n",
        "\n",
        "# no augmentation for the test data only resizing, conversion to tensor and normalization\n",
        "augmentation_test = transforms.Compose([\n",
        "                    transforms.Resize((28,28)),\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Normalize(norm_mean, norm_std),\n",
        "                    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGR6pIuMJsqK"
      },
      "source": [
        "## Splitting up data\n",
        "\n",
        "Set up datasets for training, validation and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHYTu04_yDvo"
      },
      "outputs": [],
      "source": [
        "# load the data\n",
        "train_dataset = DataClass(root=input_root, split='train', transform=augmentation_train, download=download)\n",
        "test_dataset = DataClass(root=input_root, split='test', transform=augmentation_test, download=download)\n",
        "val_dataset = DataClass(root=input_root, split='val', transform=augmentation_test, download=download)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zL9p3c52xpUB"
      },
      "outputs": [],
      "source": [
        "# Some detailed information about all splits\n",
        "print(\"===================\")\n",
        "print(train_dataset)\n",
        "print(\"===================\")\n",
        "print(val_dataset)\n",
        "print(\"===================\")\n",
        "print(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset.montage(length=20)"
      ],
      "metadata": {
        "id": "MOUtG8XucwyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPZXPqSvKNyh"
      },
      "source": [
        "## Create Dataloaders\n",
        "\n",
        "PyTorch provides template Dataloader classes for easy data handling, assigning according transforms and splits. You can find more information about how PyTorch handles datasets and data loading [here](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUURp9J01EtJ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "### encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMfm-GkQyFe3"
      },
      "outputs": [],
      "source": [
        "### the next() function returns the next item from the iterator.\n",
        "batch_images, batch_labels = next(iter(train_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7O9BTWgOyIhK"
      },
      "outputs": [],
      "source": [
        "# show all 3 channels of image 10\n",
        "print(batch_images[0].shape)\n",
        "\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(batch_images[11][0,:,:])\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(batch_images[11][1,:,:])\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "plt.imshow(batch_images[11][2,:,:])\n",
        "\n",
        "### different color maps\n",
        "### cmap='bone', cmap = 'summer', cmap = 'seismic'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "3QclrDwU6j2B"
      },
      "source": [
        "## Define a Convolutional Neural Network\n",
        "\n",
        "Pytorch makes it very easy to define a neural network. We have layers like Convolutions, ReLU non-linearity, Maxpooling etc. directly from [torch library](https://pytorch.org/docs/stable/nn.html).\n",
        "\n",
        "In this tutorial, we use The LeNet architecture introduced by LeCun et al. in their 1998 paper, [Gradient-Based Learning Applied to Document Recognition](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf). As the name of the paper suggests, the authorsâ€™ implementation of LeNet was used primarily for OCR and character recognition in documents. The LeNet architecture is straightforward and small, (in terms of memory footprint), making it perfect for teaching the basics of CNNs.\n",
        "\n",
        "To define a neural network in PyTorch one has to create a class inhereting from [torch.nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html). Crucially, this class has to include the function forward() which defines which computation should be performed at every call given a batch of inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4SswIxD6j2B",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "num_classes = 7\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=(5,5), padding=2)\n",
        "        self.nonlin1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=(5,5))\n",
        "        self.nonlin2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=(2,2))\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=16*5*5, out_features=120)\n",
        "        self.nonlin3 = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(in_features=120, out_features=84)\n",
        "        self.nonlin4 = nn.ReLU()\n",
        "        self.fc3 = nn.Linear(in_features=84, out_features=num_classes)\n",
        "        self.nonlin5 = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.nonlin1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.nonlin2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.nonlin3(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.nonlin4(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.nonlin5(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boDY7kb_crzf"
      },
      "source": [
        "You can use torchsummary to print out the architecture of your model given a certain input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sMRRaXwhcrzf"
      },
      "outputs": [],
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "model = LeNet()\n",
        "model.to(device)\n",
        "\n",
        "summary(model, input_size=(1,28,28), batch_size=127)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hf87hhWCaqp"
      },
      "source": [
        "## Homework\n",
        "\n",
        "Create a neural network capable of processing the image tensor 'img', which has only one channel. The network should contain at least one convolutional layer and one additional fully connected layer. Pay attention that within the fully connected layer the output dimension of the last convolutional layer has to fit the input dimension. Additionally, the output dimension of the fully connected layer before 'fc_fin' has to match the required input dimension of 'fc_fin'.\n",
        "\n",
        "Some hints:\n",
        "\n",
        "- Have a look at how LeNet is implemented above. Many concepts can be copied.\n",
        "- Focus on using the PyTorch's Linear, Conv2d, MaxPool2d and ReLU layers and the .view() function. You can find detailed information on these components in [PyTorch's documentation](https://pytorch.org/docs/stable/index.html).\n",
        "- Batch size does not have to be considered when designing the neural networks. PyTorch adapts the calculations automatically when provided with different batch sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ia2S8hrDCIL"
      },
      "outputs": [],
      "source": [
        "img = torch.rand((1, 1, 200, 200))\n",
        "\n",
        "output_dim = 6\n",
        "\n",
        "class LeNet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet2, self).__init__()\n",
        "\n",
        "        # --------------------\n",
        "\n",
        "        ########## Insert your layers here ##########\n",
        "\n",
        "        # --------------------\n",
        "\n",
        "        self.fc_fin = nn.Linear(in_features=48, out_features=output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # --------------------\n",
        "\n",
        "        ########## Insert your forward pass here ##########\n",
        "\n",
        "        # --------------------\n",
        "\n",
        "        x = self.fc_fin(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "\n",
        "model = LeNet2()\n",
        "\n",
        "output = model(img)\n",
        "\n",
        "if output.size(1) == 6:\n",
        "    print('The correct output size has been generated.')\n",
        "else:\n",
        "    print('The generated output size is not correct')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE_R_SSWF6Lb"
      },
      "source": [
        "## Define a Loss function\n",
        "\n",
        "Let's use a Classification Cross-Entropy loss.\n",
        "\n",
        "$H_{y'} (y) := - \\sum_{i} y_{i}' \\log (y_i)$\n",
        "\n",
        "### Median Frequency Balancing\n",
        "There are datasets which have a large imbalance in the amount of label occurrence. A prediction would be therefore biased towards stronger represented classes. As a solution, we use **Median Frequency Balancing**. Essentially this tasks the optimizer to weight examples of rare cases more highly than examples of common cases that are processed more frequently."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBCw5e67crzf"
      },
      "outputs": [],
      "source": [
        "# get the class labels of each image\n",
        "class_labels = train_dataset.labels\n",
        "# get the number of different classes\n",
        "num_classes = np.max(class_labels)+1\n",
        "# empty array for counting instance of each class\n",
        "count_labels = np.zeros(num_classes)\n",
        "# empty array for weights of each class\n",
        "class_weights = np.zeros(num_classes)\n",
        "\n",
        "# populate the count array\n",
        "for l in class_labels:\n",
        "    count_labels[l] += 1\n",
        "\n",
        "# get median count\n",
        "median_freq = np.median(count_labels)\n",
        "\n",
        "# calculate the weigths\n",
        "for i in range(num_classes):\n",
        "    class_weights[i] = median_freq/count_labels[i]\n",
        "\n",
        "# print the weights\n",
        "for i in range(num_classes):\n",
        "    print(\"class\", i, \":\", class_weights[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pPUGMq3NCnP"
      },
      "source": [
        "Now we define the loss function with the weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-Q72RJ-M84P"
      },
      "outputs": [],
      "source": [
        "class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "criterion = nn.CrossEntropyLoss(weight = class_weights)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRBdC31sF6Li"
      },
      "source": [
        "## Define the Optimizer\n",
        "\n",
        "The most common and effective optimizer currently used is **Adam: Adaptive Moments**. You can check out [the paper on it](https://arxiv.org/abs/1412.6980) for more information.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmMjYnCjF6Lk"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# now lets go back to the initial LeNet architecture\n",
        "net = LeNet()\n",
        "net = net.to(device)\n",
        "\n",
        "# and define an optimizer\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-5)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oGr-AfqF6Ln"
      },
      "source": [
        "## Network training\n",
        "\n",
        "After everything has been set up, we can now start an actual training on our dataset. To save time, for the moment we will run only ten epochs. Within the training, our dataloader is used to load a batch from our dataset. This batch is forwarded to the model. The corresponding output is compared against its labels with the chosen loss function, here called 'criterion'. Then, the loss values are backpropagated through the whole model.\n",
        "\n",
        "After, the training step a validation step is performed. Here the network is set to .eval() mode in which its weights are not being updated and consequently backprogagation is not needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IhWoB7rcrzh"
      },
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    ##### Training loop #####\n",
        "    running_loss_train = 0.0\n",
        "    num_correct_train = 0\n",
        "    num_all_train = 0\n",
        "\n",
        "    for i, data in enumerate(train_loader):\n",
        "\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), torch.squeeze(labels).to(device)\n",
        "\n",
        "        # set model to training mode\n",
        "        net.train()\n",
        "\n",
        "        # set the parameter gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # calculate the network output and its loss\n",
        "        outputs = net(inputs[:,0:1,:,:])\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # During training we need to backpropagate the loss and conduct an optimization step\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # compute running loss and accuracy\n",
        "        running_loss_train += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        num_correct_train += torch.sum(predicted == labels).item()\n",
        "        num_all_train += labels.size()[0]\n",
        "\n",
        "        training_loss = running_loss_train / num_all_train\n",
        "        training_accuracy = num_correct_train / num_all_train\n",
        "\n",
        "\n",
        "    ##### Validation loop #####\n",
        "    running_loss_val = 0.0\n",
        "    num_correct_val = 0\n",
        "    num_all_val = 0\n",
        "\n",
        "    for i, data in enumerate(val_loader):\n",
        "\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), torch.squeeze(labels).to(device)\n",
        "\n",
        "        # set model to evaluation mode\n",
        "        net.eval()\n",
        "\n",
        "        # calculate the network output and its loss\n",
        "        outputs = net(inputs[:,0:1,:,:])\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # compute running loss and accuracy\n",
        "        running_loss_val += loss\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        num_correct_val += torch.sum(predicted == labels).item()\n",
        "        num_all_val += labels.size()[0]\n",
        "\n",
        "        validation_loss = running_loss_val / num_all_val\n",
        "        validation_accuracy = num_correct_val / num_all_val\n",
        "\n",
        "    print('Epoch: {}, training loss: {:.4f}, training accuracy: {}%, validation loss: {:.4f}, validation accuracy: {}%, '.format(epoch+1, training_loss, np.round(training_accuracy, 3) * 100, validation_loss, np.round(validation_accuracy, 3) * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIbJukXZA7ap"
      },
      "source": [
        "## Homework\n",
        "After performing the training and validation of your system you are now ready to perform the inference on your test set. Implement the inference step for out dataset. Hint: It will look very similar to one the previous loops (train or validation)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIxOp-2Wcrzh"
      },
      "outputs": [],
      "source": [
        "running_loss_test = 0.0\n",
        "num_correct_test = 0\n",
        "num_all_test = 0\n",
        "\n",
        "for i, data in enumerate(test_loader):\n",
        "\n",
        "    ########## Implement the data loading and prediction on the test set ##########\n",
        "\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    print(type(labels))\n",
        "    net.eval()  # Set model to validation mode\n",
        "\n",
        "    # -------------------------------\n",
        "    # Calculate the network output and its loss\n",
        "    outputs = net(inputs[:,0:1,:,:])\n",
        "    loss = criterion(outputs, torch.argmax(labels, 1))\n",
        "\n",
        "    ########## ------------------------------- ##########\n",
        "\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    num_correct_test += torch.sum(predicted == labels).item()\n",
        "    num_all_test += labels.size()[0]\n",
        "    running_loss_test += loss.item()\n",
        "\n",
        "    test_loss = running_loss_test / num_all_test\n",
        "    test_accuracy = num_correct_test / num_all_test\n",
        "\n",
        "print('Loss for test set is {}'.format(test_loss))\n",
        "print('Test accuracy of the network: {}%'.format(np.round(test_accuracy, 3)*100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('default')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "vscode": {
      "interpreter": {
        "hash": "62f47e0a940d9130cb9d8ad31b00082fdc26fbada418265db41289562a6ad16c"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}