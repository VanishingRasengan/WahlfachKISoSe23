{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "HFeaM-1W3Dwx"
      ],
      "authorship_tag": "ABX9TyPJygYTLruy++6/vmsFTva8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VanishingRasengan/WahlfachKISoSe23/blob/main/Lektion_4_Python_f%C3%BCr_Mediziner\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regression\n",
        "Now we're going to check out the other type of supervised learning: regression. In regression tasks, the target variable typically has continuous values, such as a country's GDP, or the price of a house."
      ],
      "metadata": {
        "id": "IV0sydD_5wOc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this chapter, you will work with a dataset called sales_df, which contains information on advertising campaign expenditure across different media types, and the number of dollars generated in sales for the respective campaign. First we import the dataset."
      ],
      "metadata": {
        "id": "U6IkrdmN8fVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the pathlib module - a handy library for working with the local file system in an object oriented way\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# creating a path object of our data directory within the mounted Google Drive\n",
        "sales_path = Path('/content/')\n",
        "\n",
        "### to download the .csv file\n",
        "!pip install wget\n",
        "import wget\n",
        "wget.download('https://assets.datacamp.com/production/repositories/5981/datasets/0013cbcdf127f3b44e855eb1df754b9dc3526d02/advertising_and_sales_clean.csv')\n",
        "\n",
        "# create another pathlib object with the path to the csv file\n",
        "sales_csv_path = sales_path / 'advertising_and_sales_clean.csv'\n",
        "sales_df = pd.read_csv(sales_csv_path)\n",
        "sales_df = sales_df.drop(columns=\"influencer\")"
      ],
      "metadata": {
        "id": "87LCw3zc81OR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "576261b6-4334-4f36-e5a7-75a8c9fa127d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9657 sha256=07e0c90b527fcbbf2497fdb8631a20f1f5cc32925724f8050a8d80f3722eb2c6\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Have a look on the dataset you are goiong to work with:"
      ],
      "metadata": {
        "id": "qS7u9TQ_Uexc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "UrJdbw4_UjWf",
        "outputId": "f6f85e25-150c-4eaa-ad0a-4a31674b6ea1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           tv     radio  social_media      sales\n",
              "0     16000.0   6566.23       2907.98   54732.76\n",
              "1     13000.0   9237.76       2409.57   46677.90\n",
              "2     41000.0  15886.45       2913.41  150177.83\n",
              "3     83000.0  30020.03       6922.30  298246.34\n",
              "4     15000.0   8437.41       1406.00   56594.18\n",
              "...       ...       ...           ...        ...\n",
              "4541  26000.0   4472.36        717.09   94685.87\n",
              "4542  71000.0  20610.69       6545.57  249101.92\n",
              "4543  44000.0  19800.07       5096.19  163631.46\n",
              "4544  71000.0  17534.64       1940.87  253610.41\n",
              "4545  42000.0  15966.69       5046.55  148202.41\n",
              "\n",
              "[4546 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-84e0368f-d57a-4d7c-97b1-7c2887f476c2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tv</th>\n",
              "      <th>radio</th>\n",
              "      <th>social_media</th>\n",
              "      <th>sales</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>16000.0</td>\n",
              "      <td>6566.23</td>\n",
              "      <td>2907.98</td>\n",
              "      <td>54732.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13000.0</td>\n",
              "      <td>9237.76</td>\n",
              "      <td>2409.57</td>\n",
              "      <td>46677.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>41000.0</td>\n",
              "      <td>15886.45</td>\n",
              "      <td>2913.41</td>\n",
              "      <td>150177.83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>83000.0</td>\n",
              "      <td>30020.03</td>\n",
              "      <td>6922.30</td>\n",
              "      <td>298246.34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15000.0</td>\n",
              "      <td>8437.41</td>\n",
              "      <td>1406.00</td>\n",
              "      <td>56594.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4541</th>\n",
              "      <td>26000.0</td>\n",
              "      <td>4472.36</td>\n",
              "      <td>717.09</td>\n",
              "      <td>94685.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4542</th>\n",
              "      <td>71000.0</td>\n",
              "      <td>20610.69</td>\n",
              "      <td>6545.57</td>\n",
              "      <td>249101.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4543</th>\n",
              "      <td>44000.0</td>\n",
              "      <td>19800.07</td>\n",
              "      <td>5096.19</td>\n",
              "      <td>163631.46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4544</th>\n",
              "      <td>71000.0</td>\n",
              "      <td>17534.64</td>\n",
              "      <td>1940.87</td>\n",
              "      <td>253610.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4545</th>\n",
              "      <td>42000.0</td>\n",
              "      <td>15966.69</td>\n",
              "      <td>5046.55</td>\n",
              "      <td>148202.41</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4546 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-84e0368f-d57a-4d7c-97b1-7c2887f476c2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-84e0368f-d57a-4d7c-97b1-7c2887f476c2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-84e0368f-d57a-4d7c-97b1-7c2887f476c2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating features\n",
        "You will use the advertising expenditure as features to predict sales values, initially working with the \"radio\" column. However, before you make any predictions you will need to create the feature and target arrays, reshaping them to the correct format for scikit-learn."
      ],
      "metadata": {
        "id": "nG6HXU-r9u60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Create X from the radio column's values\n",
        "X = sales_df[\"radio\"].values\n",
        "\n",
        "# Create y from the sales column's values\n",
        "y = sales_df[\"sales\"].values\n",
        "\n",
        "# Reshape X\n",
        "X = X.reshape(-1, 1)\n",
        "\n",
        "# Check the shape of the features and targets\n",
        "print(X.shape, y.shape)"
      ],
      "metadata": {
        "id": "OX6Oy9KDLo-S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0178b153-869b-4152-cf3f-fb95a4923417"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4546, 1) (4546,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a linear regression model\n",
        "Now you have created your feature and target arrays, you will train a linear regression model on all feature and target values.\n",
        "\n",
        "As the goal is to assess the relationship between the feature and target values there is no need to split the data into training and test sets.\n",
        "\n",
        "- Import LinearRegression.\n",
        "- Instantiate a linear regression model.\n",
        "- Predict sales values using X, storing as predictions.\n"
      ],
      "metadata": {
        "id": "fiZni14P-EHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LinearRegression\n",
        "from ____.____ import ____\n",
        "\n",
        "# Create the model\n",
        "reg = ____()\n",
        "\n",
        "# Fit the model to the data\n",
        "____\n",
        "\n",
        "# Make predictions\n",
        "predictions = ____\n",
        "\n",
        "print(predictions[:5])"
      ],
      "metadata": {
        "id": "nhi_FVu6LrgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing a linear regression model\n",
        "Now you have built your linear regression model and trained it using all available observations, you can visualize how well the model fits the data. This allows you to interpret the relationship between `radio` advertising expenditure and `sales` values.\n",
        "\n",
        "- Import matplotlib.pyplot as plt.\n",
        "- Create a scatter plot visualizing y against X, with observations in blue.\n",
        "- Draw a red line plot displaying the predictions against X.\n",
        "- Display the plot.\n"
      ],
      "metadata": {
        "id": "gJmOVN2N-iAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import matplotlib.pyplot\n",
        "import ____.____ as ____\n",
        "\n",
        "# Create scatter plot\n",
        "plt.scatter(____, ____, color=\"____\")\n",
        "\n",
        "# Create line plot\n",
        "plt.plot(____, ____, color=\"____\")\n",
        "plt.xlabel(\"Radio Expenditure ($)\")\n",
        "plt.ylabel(\"Sales ($)\")\n",
        "\n",
        "# Display the plot\n",
        "plt.____()"
      ],
      "metadata": {
        "id": "SOwkGLmILs7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fit and predict for regression\n",
        "Now you have seen how linear regression works, your task is to create a multiple linear regression model using all of the features in the sales_df dataset. You will then use this model to predict sales based on the values of the test features.\n",
        "\n",
        "- Create X, an array containing values of all features in sales_df, and y, containing all values from the \"sales\" column.\n",
        "- Instantiate a linear regression model.\n",
        "- Fit the model to the training data.\n",
        "- Create `y_pred`, making predictions for sales using the test features.\n"
      ],
      "metadata": {
        "id": "d3Ky5Ug8_eAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create X and y arrays\n",
        "X = sales_df.____(\"____\", axis=____).____\n",
        "y = sales_df[\"____\"].____\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Instantiate the model\n",
        "reg = ____\n",
        "\n",
        "# Fit the model to the data\n",
        "____\n",
        "\n",
        "# Make predictions\n",
        "y_pred = reg.____(____)\n",
        "print(\"Predictions: {}, Actual Values: {}\".format(y_pred[:2], y_test[:2]))"
      ],
      "metadata": {
        "id": "gclw8jiELuWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regression performance\n",
        "Now you have fit a model, reg, using all features from sales_df, and made predictions of sales values, you can evaluate performance using some common regression metrics.\n",
        "\n",
        "Your task is to find out how well the features can explain the variance in the target values, along with assessing the model's ability to make predictions on unseen data.\n",
        "\n",
        "- Import mean_squared_error.\n",
        "- Calculate the model's R-squared score by passing the test feature values and the test target values to an appropriate method.\n",
        "- Calculate the model's root mean squared error using y_test and y_pred.\n",
        "- Print r_squared and rmse.\n"
      ],
      "metadata": {
        "id": "h9vgoepUBTGX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import mean_squared_error\n",
        "from ____.____ import ____\n",
        "\n",
        "# Compute R-squared\n",
        "r_squared = reg.____(____, ____)\n",
        "\n",
        "# Compute RMSE\n",
        "rmse = ____(____, ____, squared=____)\n",
        "\n",
        "# Print the metrics\n",
        "print(\"R^2: {}\".format(____))\n",
        "print(\"RMSE: {}\".format(____))"
      ],
      "metadata": {
        "id": "OdiHIHmULwO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Cross-validation for R-squared\n",
        "Cross-validation is a vital approach to evaluating a model. It maximizes the amount of data that is available to the model, as the model is not only trained but also tested on all of the available data.\n",
        "\n",
        "In this exercise, you will build a linear regression model, then use 6-fold cross-validation to assess its accuracy for predicting sales using social media advertising expenditure. You will display the individual score for each of the six-folds.\n",
        "\n",
        "\n",
        "- Import KFold and cross_val_score.\n",
        "- Create kf by calling KFold(), setting the number of splits to six, shuffle to True, and setting a seed of 5.\n",
        "- Perform cross-validation using reg on X and y, passing kf to cv.\n",
        "- Print the cv_scores.\n"
      ],
      "metadata": {
        "id": "cJjT05m1DqiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = sales_df.drop(['tv', 'sales'], axis=1).values\n",
        "y = sales_df[\"sales\"].values"
      ],
      "metadata": {
        "id": "vZhDSgXtIEwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules\n",
        "from ____.____ import ____, ____\n",
        "\n",
        "# Create a KFold object\n",
        "kf = ____(n_splits=____, shuffle=____, random_state=____)\n",
        "\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Compute 6-fold cross-validation scores\n",
        "cv_scores = ____(____, ____, ____, cv=____)\n",
        "\n",
        "# Print scores\n",
        "print(____)"
      ],
      "metadata": {
        "id": "nWnLuo6vLxgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing cross-validation metrics\n",
        "Now you have performed cross-validation, it's time to analyze the results.\n",
        "\n",
        "You will display the mean, standard deviation, and 95% confidence interval for cv_results.\n",
        "\n",
        "\n",
        "- Calculate and print the mean of the results.\n",
        "- Calculate and print the standard deviation of cv_results.\n",
        "- Display the 95% confidence interval for your results using np.quantile().\n"
      ],
      "metadata": {
        "id": "6oggQ0a4I-f0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the mean\n",
        "print(____(____))\n",
        "\n",
        "# Print the standard deviation\n",
        "print(____(____))\n",
        "\n",
        "# Print the 95% confidence interval\n",
        "print(____(____, [____, ____]))"
      ],
      "metadata": {
        "id": "5dEckq9hL0Wx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularized regression: Ridge\n",
        "Ridge regression performs regularization by computing the squared values of the model parameters multiplied by alpha and adding them to the loss function.\n",
        "\n",
        "In this exercise, you will fit ridge regression models over a range of different alpha values, and print their scores. You will use all of the features in the sales_df dataset to predict \"sales\".\n",
        "\n",
        "A variable called alphas has been provided as a list containing different alpha values, which you will loop through to generate scores.\n",
        "\n",
        "- Import Ridge.\n",
        "- Instantiate Ridge, setting alpha equal to alpha.\n",
        "- Fit the model to the training data.\n",
        "- Calculate the R-squared score for each iteration of ridge."
      ],
      "metadata": {
        "id": "l2B4BXWPJS51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Ridge\n",
        "from ____.____ import ____\n",
        "alphas = [0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0]\n",
        "ridge_scores = []\n",
        "for alpha in alphas:\n",
        "\n",
        "  # Create a Ridge regression model\n",
        "  ridge = ____\n",
        "\n",
        "  # Fit the data\n",
        "  ____\n",
        "\n",
        "  # Obtain R-squared\n",
        "  score = ____\n",
        "  ridge_scores.append(score)\n",
        "print(ridge_scores)"
      ],
      "metadata": {
        "id": "Gqgqk2SLL17R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The scores don't appear to change much as alpha increases, which is indicative of how well the features explain the variance in the target—even by heavily penalizing large coefficients, underfitting does not occur!"
      ],
      "metadata": {
        "id": "GFxWC2xPJolN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lasso regression for feature importance\n",
        "Lasso regression can be used to identify important features in a dataset.\n",
        "\n",
        "In this exercise, you will fit a lasso regression model to the sales_df data and plot the model's coefficients.\n",
        "\n",
        "\n",
        "- Import Lasso from sklearn.linear_model.\n",
        "- Instantiate a Lasso regressor with an alpha of 0.3.\n",
        "- Fit the model to the data.\n",
        "- Compute the model's coefficients, storing as lasso_coef.\n"
      ],
      "metadata": {
        "id": "nnTAc9twJqh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = sales_df.drop(\"sales\", axis=1).values\n",
        "y = sales_df[\"sales\"].values"
      ],
      "metadata": {
        "id": "bXG7U7z_JOy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Lasso\n",
        "from ____.____ import ____\n",
        "\n",
        "# Instantiate a lasso regression model\n",
        "lasso = ____\n",
        "\n",
        "# Fit the model to the data\n",
        "____\n",
        "\n",
        "# Compute and print the coefficients\n",
        "lasso_coef = ____\n",
        "print(lasso_coef)\n",
        "plt.bar(sales_columns, lasso_coef)\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "G-XagLpPL33R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "See how the figure makes it clear that expenditure on TV advertising is the most important feature in the dataset to predict sales values! In the next chapter, we will learn how to further assess and improve our model's performance!"
      ],
      "metadata": {
        "id": "r2ejsCcSKCsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning Your Model\n",
        "Having trained models, now you will learn how to evaluate them. In this chapter, you will be introduced to several metrics along with a visualization technique for analyzing classification model performance using scikit-learn. You will also learn how to optimize classification and regression models through the use of hyperparameter tuning."
      ],
      "metadata": {
        "id": "pG2hedVrKIO_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assessing a diabetes prediction classifier\n",
        "\n",
        "In this chapter you'll work with the diabetes_df dataset introduced previously.\n",
        "\n",
        "The goal is to predict whether or not each individual is likely to have diabetes based on the features body mass index (BMI) and age (in years). Therefore, it is a binary classification problem. A target value of 0 indicates that the individual does not have diabetes, while a value of 1 indicates that the individual does have diabetes.\n",
        "\n",
        "First we import the `diabetes_df`:"
      ],
      "metadata": {
        "id": "5OZJGuyIMgLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the pathlib module - a handy library for working with the local file system in an object oriented way\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "\n",
        "# creating a path object of our data directory within the mounted Google Drive\n",
        "diabetes_path = Path('/content/')\n",
        "\n",
        "### to download the .csv file\n",
        "import wget\n",
        "wget.download('https://assets.datacamp.com/production/repositories/5981/datasets/3d7b5bbdc7e91636cb1f9b62d9ca2a3959ce8aab/diabetes_clean.csv')\n",
        "\n",
        "# create another pathlib object with the path to the csv file\n",
        "diabetes_csv_path = diabetes_path / 'diabetes_clean.csv'\n",
        "diabetes_df = pd.read_csv(diabetes_csv_path)"
      ],
      "metadata": {
        "id": "xZItK-yRKoGG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will fit the model, make predictions on the test set, then produce a confusion matrix and classification report.\n",
        "\n",
        "- Split the dataframe into `X_train`, `X_test`, `y_train`, and `y_test`\n",
        "- Import `confusion_matrix` and `classification_report`.\n",
        "- Fit the model to the training data.\n",
        "- Predict the labels of the test set, storing the results as y_pred.\n",
        "- Compute and print the confusion matrix and classification report for the test labels versus the predicted labels.\n"
      ],
      "metadata": {
        "id": "KseQcj6gK4Bu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into X_train, X_test, y_train, and y_test\n",
        "X = diabetes_df.drop(\"diabetes\", axis=1).values\n",
        "y = diabetes_df[\"diabetes\"].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Import confusion matrix\n",
        "____\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=6)\n",
        "\n",
        "# Fit the model to the training data\n",
        "____\n",
        "\n",
        "# Predict the labels of the test data: y_pred\n",
        "y_pred = ____\n",
        "\n",
        "# Generate the confusion matrix and classification report\n",
        "print(____(____, ____))\n",
        "print(____(____, ____))"
      ],
      "metadata": {
        "id": "yY383ffTL5RS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model produced 38 true positives and 27 false positives, meaning precision was less than 50%, which is confirmed in the classification report. The output also shows a better F1-score for the zero class, which represents individuals who do not have diabetes."
      ],
      "metadata": {
        "id": "GWTuPrF9MLz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building a logistic regression model\n",
        "\n",
        "In this exercise, you will build a logistic regression model using all features in the diabetes_df dataset. The model will be used to predict the probability of individuals in the test set having a diabetes diagnosis.\n",
        "\n",
        "\n",
        "- Import LogisticRegression.\n",
        "- Instantiate a logistic regression model, logreg.\n",
        "- Fit the model to the training data.\n",
        "- Predict the probabilities of each individual in the test set having a diabetes diagnosis, storing the array of positive probabilities as y_pred_probs.\n"
      ],
      "metadata": {
        "id": "icp0A7N2MmrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import LogisticRegression\n",
        "____\n",
        "\n",
        "# Instantiate the model\n",
        "logreg = ____\n",
        "\n",
        "# Fit the model\n",
        "____\n",
        "\n",
        "# Predict probabilities\n",
        "y_pred_probs = logreg.____(____)[____, ____]\n",
        "\n",
        "print(y_pred_probs[:10])"
      ],
      "metadata": {
        "id": "zE5gQhn_L9ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The ROC curve\n",
        "Now you have built a logistic regression model for predicting diabetes status, you can plot the ROC curve to visualize how the true positive rate and false positive rate vary as the decision threshold changes. You will create a ROC curve and then interpret the results.\n",
        "\n",
        "- Import roc_curve.\n",
        "- Calculate the ROC curve values, using y_test and y_pred_probs, and unpacking the results into fpr, tpr, and thresholds.\n",
        "- Plot true positive rate against false positive rate.\n"
      ],
      "metadata": {
        "id": "DB0GCGbJM4QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import roc_curve\n",
        "from sklearn.metrics import roc_curve\n",
        "\n",
        "# Generate ROC curve values: fpr, tpr, thresholds\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Plot tpr against fpr\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Diabetes Prediction')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ErHs5hZhL_ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROC curve is above the dotted line, so the model performs better than randomly guessing the class of each observation."
      ],
      "metadata": {
        "id": "SWXJyexINLYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC AUC\n",
        "\n",
        "The ROC curve you plotted in the last exercise looked promising.\n",
        "\n",
        "Now you will compute the area under the ROC curve, along with the other classification metrics you have used previously.\n",
        "\n",
        "- Import roc_auc_score.\n",
        "- Calculate and print the ROC AUC score, passing the test labels and the predicted positive class probabilities.\n",
        "- Calculate and print the confusion matrix.\n",
        "- Call classification_report()."
      ],
      "metadata": {
        "id": "V259xaYbMXCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import roc_auc_score\n",
        "____\n",
        "\n",
        "# Calculate roc_auc_score\n",
        "print(____(____, ____))\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "print(____(____, ____))\n",
        "\n",
        "# Calculate the classification report\n",
        "print(____(____, ____))"
      ],
      "metadata": {
        "id": "P2fXlJKeKlhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning with GridSearchCV\n",
        "\n",
        "Now you have seen how to perform grid search hyperparameter tuning, you are going to build a lasso regression model with optimal hyperparameters to predict blood glucose levels using the features in the diabetes_df dataset.\n",
        "\n",
        "X_train, X_test, y_train, and y_test have been preloaded for you. A KFold() object has been created and stored for you as kf, along with a lasso regression model as lasso.\n",
        "\n",
        "- Import GridSearchCV.\n",
        "- Set up a parameter grid for \"alpha\", using np.linspace() to create 20 evenly spaced values ranging from 0.00001 to 1.\n",
        "- Call GridSearchCV(), passing lasso, the parameter grid, and setting cv equal to kf.\n",
        "- Fit the grid search object to the training data to perform a cross-validated grid search."
      ],
      "metadata": {
        "id": "JsE4jdWCMv5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import GridSearchCV\n",
        "____\n",
        "\n",
        "# Set up the parameter grid\n",
        "param_grid = {\"____\": np.linspace(____, ____, ____)}\n",
        "\n",
        "# Instantiate lasso_cv\n",
        "lasso_cv = ____(____, ____, cv=____)\n",
        "\n",
        "# Fit to the training data\n",
        "____\n",
        "print(\"Tuned lasso paramaters: {}\".format(lasso_cv.best_params_))\n",
        "print(\"Tuned lasso score: {}\".format(lasso_cv.best_score_))"
      ],
      "metadata": {
        "id": "7rtCOeQVKqPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well done! Unfortunately, the best model only has an R-squared score of 0.33, highlighting that using the optimal hyperparameters does not guarantee a high performing model!"
      ],
      "metadata": {
        "id": "X5KOs7axNLNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter tuning with RandomizedSearchCV\n",
        "\n",
        "As you saw, GridSearchCV can be computationally expensive, especially if you are searching over a large hyperparameter space. In this case, you can use RandomizedSearchCV, which tests a fixed number of hyperparameter settings from specified probability distributions.\n",
        "\n",
        "- Create params, adding \"l1\" and \"l2\" as penalty values, setting C to a range of 50 float values between 0.1 and 1.0, and class_weight to either \"balanced\" or a dictionary containing 0:0.8, 1:0.2.\n",
        "- Create the Randomized Search CV object, passing the model and the parameters, and setting cv equal to kf.\n",
        "- Fit logreg_cv to the training data.\n",
        "- Print the model's best parameters and accuracy score.\n",
        "\n",
        "Die Schritte habe ich für euch aber schon unten gecoded!"
      ],
      "metadata": {
        "id": "gnJP7K9sNOby"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U scikit-learn"
      ],
      "metadata": {
        "id": "OdxkyC3NMArA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Create the parameter space\n",
        "params = {\"penalty\": [\"l1\", \"l2\"],\n",
        "         \"tol\": np.linspace(0.0001, 1.0, 50),\n",
        "         \"C\": np.linspace(0.1, 1.0, 50),\n",
        "         \"class_weight\": [\"balanced\", {0:0.8, 1:0.2}]}\n",
        "\n",
        "# Instantiate the RandomizedSearchCV object\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "logreg_cv = RandomizedSearchCV(logreg, params, cv=kf)\n",
        "\n",
        "# Fit the data to the model\n",
        "logreg_cv.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "DwhrSO_yK1gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the tuned parameters and score\n",
        "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_))\n",
        "print(\"Tuned Logistic Regression Best Accuracy Score: {}\".format(logreg_cv.best_score_))"
      ],
      "metadata": {
        "id": "-Ztb5D23MNiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great searching! Even without exhaustively trying every combination of hyperparameters, the model has an accuracy of over 70% on the test set!"
      ],
      "metadata": {
        "id": "GCsEgy-NNtFK"
      }
    }
  ]
}